{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d312e52-2abe-4a98-b8fc-54929371a3af",
   "metadata": {},
   "source": [
    "# Generating STAC Machine Learning Model (MLM) Items from a YAML Config Folder\n",
    "\n",
    "This notebook reads all YAML configuration files in the [`configs/downscaling`](../configs/downscaling) folder\n",
    "and creates a STAC Item using the [MLM Extension](https://github.com/stac-extensions/mlm).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3da74-5c5f-463f-87b1-8886a47b3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pystac stac-model==0.4.0 resoterre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb58d6-0db0-427a-99df-56e515a55487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "\n",
    "import pystac\n",
    "import shapely\n",
    "import yaml\n",
    "from dateutil.parser import parse as parse_dt\n",
    "from pystac import STACValidationError\n",
    "from pystac.extensions.datacube import DatacubeExtension, Dimension, Variable\n",
    "from stac_model.input import InputStructure, ModelInput\n",
    "from stac_model.output import ModelOutput, ModelResult\n",
    "from stac_model.schema import MLModelExtension, MLModelProperties\n",
    "\n",
    "from resoterre.ml.network_manager import nb_of_parameters\n",
    "from resoterre.ml.neural_networks_unet import UNet, UNetConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39915f-22d1-4c39-8562-bfbcd2d8d9a9",
   "metadata": {},
   "source": [
    "## Utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1489801-604c-49bb-a7b9-9c82a1d844fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_aggregator(config_folder: str | Path) -> dict:\n",
    "    \"\"\"\n",
    "    Aggregate all YAML configuration files in a folder into a single dictionary.\n",
    "\n",
    "    Args:\n",
    "        config_folder (str | Path): Path to the folder containing YAML config files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        dict: Aggregated configuration from all YAML files.\n",
    "    \"\"\"\n",
    "    config_folder = Path(config_folder)\n",
    "    if not config_folder.exists():\n",
    "        raise FileNotFoundError(f\"Config folder not found: {config_folder}\")\n",
    "\n",
    "    aggregated_cfg = {}\n",
    "\n",
    "    for yaml_file in sorted(config_folder.glob(\"*.yaml\")):\n",
    "        with yaml_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            cfg = yaml.safe_load(f) or {}  # treat empty YAML as empty dict\n",
    "            aggregated_cfg.update(cfg)\n",
    "\n",
    "    return aggregated_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25bb219-a3fe-4c15-83f3-dfdffafb3ec6",
   "metadata": {},
   "source": [
    "## Function to convert a config to STAC item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160019e2-cd05-431d-beb1-1201903443c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stac_item_from_config(yaml_config: dict):\n",
    "    \"\"\"\n",
    "    Create a STAC Item (and associated Collection) from a YAML model configuration dicttionary.\n",
    "\n",
    "    Args:\n",
    "        yaml_config (dict): Aggregated YAML configuration dictionary describing the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pystac.Item: The generated STAC Item.\n",
    "    \"\"\"\n",
    "    cfg = yaml_config\n",
    "\n",
    "    train_cfg = cfg[\"train_dataset\"]\n",
    "    model_path = cfg[\"path_models\"] + \"/unet-model.ckpt\"\n",
    "    model_name = \"UNet\"\n",
    "    in_channels = cfg[\"networks\"][\"UNet\"][\"in_channels\"]\n",
    "    out_channels = cfg[\"networks\"][\"UNet\"][\"out_channels\"]\n",
    "    depth = cfg[\"networks\"][\"UNet\"][\"depth\"]\n",
    "    initial_nb_of_hidden_channels = cfg[\"networks\"][\"UNet\"][\"initial_nb_of_hidden_channels\"]\n",
    "\n",
    "    # --- Model architecture and parameters ---\n",
    "    config = UNetConfig(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        depth=depth,\n",
    "        initial_nb_of_hidden_channels=initial_nb_of_hidden_channels,\n",
    "    )\n",
    "    model = UNet(**asdict(config))\n",
    "    nb_params = nb_of_parameters(model)\n",
    "    module = model.__class__.__module__\n",
    "    class_name = model.__class__.__name__\n",
    "    arch = f\"{module}.{class_name}\"\n",
    "    framework = cfg[\"framework\"]\n",
    "    framework_version = cfg[\"framework_version\"]\n",
    "\n",
    "    # --- Input/Output shapes ---\n",
    "    input_variables = train_cfg.get(\"rdps_variables\", [])\n",
    "    output_variables = train_cfg.get(\"hrdps_variables\", [])\n",
    "    height, width = 64, 64  # TODO: Add to config\n",
    "\n",
    "    # --- Input structure ---\n",
    "    input_struct = InputStructure(\n",
    "        shape=[-1, len(input_variables), height, width],\n",
    "        dim_order=[\"time\", \"variables\", \"latitude\", \"longitude\"],\n",
    "        data_type=\"float32\",\n",
    "    )\n",
    "\n",
    "    model_input = ModelInput(name=\"rdps_inputs\", variables=input_variables, input=input_struct)\n",
    "\n",
    "    # --- Output structure ---\n",
    "    result_struct = ModelResult(\n",
    "        shape=[-1, len(output_variables), height, width],\n",
    "        dim_order=[\"time\", \"variables\", \"latitude\", \"longitude\"],\n",
    "        data_type=\"float32\",\n",
    "    )\n",
    "\n",
    "    model_output = ModelOutput(\n",
    "        name=\"hrdps_outputs\",\n",
    "        variables=output_variables,\n",
    "        tasks=[\"super-resolution\", \"downscaling\"],\n",
    "        result=result_struct,\n",
    "    )\n",
    "\n",
    "    # --- ML Model Properties ---\n",
    "    ml_model_meta = MLModelProperties(\n",
    "        name=f\"{model_name} RDPS HRDPS Downscaling\",\n",
    "        architecture=arch,\n",
    "        tasks={\"super-resolution\", \"downscaling\"},\n",
    "        framework=framework,\n",
    "        framework_version=framework_version,\n",
    "        accelerator=cfg.get(\"device\", \"cuda\"),\n",
    "        pretrained=True,\n",
    "        pretrained_source=\"Custom RDPS-HRDPS dataset\",\n",
    "        input=[model_input],\n",
    "        output=[model_output],\n",
    "        total_parameters=nb_params,\n",
    "    )\n",
    "\n",
    "    # TODO Validate and add preprocessing function\n",
    "\n",
    "    # --- Assets ---\n",
    "    assets = {\n",
    "        \"model\": pystac.Asset(\n",
    "            title=f\"{model_name} checkpoint\",\n",
    "            description=f\"{model_name} trained on RDPS HRDPS downscaling task.\",\n",
    "            href=model_path,\n",
    "            media_type=\"application/octet-stream; application/pytorch\",\n",
    "            roles=[\"mlm:model\", \"mlm:weights\"],\n",
    "            extra_fields={\"mlm:artifact_type\": \"torch.save\"},\n",
    "        ),\n",
    "        \"source_code\": pystac.Asset(\n",
    "            title=f\"Source code for {model_name}\",\n",
    "            description=\"GitHub repo of the PyTorch model\",\n",
    "            href=\"https://github.com/Ouranosinc/resoterre\",\n",
    "            media_type=\"text/html\",\n",
    "            roles=[\"mlm:source_code\", \"code\"],\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # --- Temporal / spatial extent ---\n",
    "    start_dt = parse_dt(train_cfg[\"start_datetime\"])\n",
    "    end_dt = parse_dt(train_cfg[\"end_datetime\"])\n",
    "    start_dt_str = start_dt.isoformat() + \"Z\"\n",
    "    end_dt_str = end_dt.isoformat() + \"Z\"\n",
    "\n",
    "    bbox = [-7.88219, 37.13739, 27.91165, 58.21798]\n",
    "    geometry = shapely.geometry.Polygon.from_bounds(*bbox).__geo_interface__\n",
    "\n",
    "    # --- STAC Catalog ---\n",
    "    catalog_href = \"./catalog.json\"  # Catalog file (create if missing)\n",
    "    if not Path(catalog_href).exists():\n",
    "        catalog = pystac.Catalog(\n",
    "            id=\"ml-model-catalog\",\n",
    "            description=\"Catalog for ML model collections\",\n",
    "            title=\"ML Model Catalog\",\n",
    "        )\n",
    "        catalog.set_self_href(catalog_href)\n",
    "        catalog.save()\n",
    "    else:\n",
    "        catalog = pystac.Catalog.from_file(catalog_href)\n",
    "\n",
    "    # --- STAC Collection ---\n",
    "    collection_name = \"ml-model-package\"\n",
    "    collection = pystac.Collection(\n",
    "        id=collection_name,\n",
    "        title=\"Machine Learning Model packaging\",\n",
    "        description=\"Collection of ML model items\",\n",
    "        strategy=pystac.layout.AsIsLayoutStrategy(),\n",
    "        extent=pystac.Extent(\n",
    "            spatial=pystac.SpatialExtent([bbox]),\n",
    "            temporal=pystac.TemporalExtent([[start_dt, end_dt]]),\n",
    "        ),\n",
    "    )\n",
    "    collection_href = \"./ml-model-package/collection.json\"\n",
    "    collection.set_self_href(collection_href)\n",
    "\n",
    "    # --- STAC Item ---\n",
    "    item_name = f\"{model_name.lower()}_rdps_to_hrdps\"\n",
    "    item = pystac.Item(\n",
    "        id=item_name,\n",
    "        collection=collection.id,\n",
    "        geometry=geometry,\n",
    "        bbox=bbox,\n",
    "        datetime=None,\n",
    "        properties={\n",
    "            \"description\": f\"{model_name} trained to downscale RDPS meteorological data to HRDPS resolution.\",\n",
    "            \"start_datetime\": start_dt_str,\n",
    "            \"end_datetime\": end_dt_str,\n",
    "            \"datetime\": None,\n",
    "        },\n",
    "        assets=assets,\n",
    "        extra_fields={\"mlm:entrypoint\": arch},  # Path to the model class\n",
    "        stac_extensions=[\n",
    "            MLModelExtension.get_schema_uri(),\n",
    "            \"https://stac-extensions.github.io/datacube/v2.3.0/schema.json\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # --- Apply ML Model Extension ---\n",
    "    item_mlm = MLModelExtension.ext(item, add_if_missing=True)\n",
    "    item_mlm.apply(ml_model_meta.model_dump(by_alias=True, exclude_unset=True, exclude_defaults=True))\n",
    "\n",
    "    # --- Apply Datacube Extension ---\n",
    "    item_dc = DatacubeExtension.ext(item_mlm.item, add_if_missing=True)\n",
    "\n",
    "    # --- Define cube:dimensions ---\n",
    "\n",
    "    levels = [850, 700, 500, 250]  # allowed pressures\n",
    "\n",
    "    dimensions = {\n",
    "        \"time\": Dimension(\n",
    "            properties={\n",
    "                \"type\": \"temporal\",\n",
    "                \"description\": \"Time dimension\",\n",
    "                \"extent\": [start_dt_str, end_dt_str],\n",
    "                \"unit\": \"s\",\n",
    "            }\n",
    "        ),\n",
    "        \"latitude\": Dimension(\n",
    "            properties={\n",
    "                \"type\": \"spatial\",\n",
    "                \"description\": \"Latitude\",\n",
    "                \"extent\": [bbox[1], bbox[3]],\n",
    "                \"axis\": \"y\",\n",
    "                \"unit\": \"degree\",\n",
    "                \"reference_system\": \"EPSG:4326\",\n",
    "            }\n",
    "        ),\n",
    "        \"longitude\": Dimension(\n",
    "            properties={\n",
    "                \"type\": \"spatial\",\n",
    "                \"description\": \"Longitude\",\n",
    "                \"extent\": [bbox[0], bbox[2]],\n",
    "                \"axis\": \"x\",\n",
    "                \"unit\": \"degree\",\n",
    "                \"reference_system\": \"EPSG:4326\",\n",
    "            }\n",
    "        ),\n",
    "        \"level\": Dimension(\n",
    "            properties={\n",
    "                \"type\": \"spatial\",\n",
    "                \"description\": \"Pressure levels\",\n",
    "                \"extent\": [min(levels), max(levels)],\n",
    "                \"values\": levels,\n",
    "                \"axis\": \"z\",\n",
    "                \"unit\": \"hPa\",\n",
    "            }\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # --- Define cube:variables ---\n",
    "    variables = {}\n",
    "    for var in input_variables + output_variables:\n",
    "        if var in [\"TT_model_levels\", \"HU850\", \"GZ500\", \"PC\", \"HRDPS_P_TT_10000\"]:\n",
    "            dims = [\"time\", \"latitude\", \"longitude\", \"level\"]\n",
    "        elif var in [\"PR\", \"HRDPS_P_PR_SFC\"]:\n",
    "            dims = [\"time\", \"latitude\", \"longitude\"]  # Surface-level, no vertical\n",
    "        variables[var] = Variable(\n",
    "            properties={\n",
    "                \"dimensions\": dims,\n",
    "                \"type\": \"data\",\n",
    "                \"data_type\": \"float32\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # --- Apply dimensions and variables to Item ---\n",
    "    item_mlm = MLModelExtension.ext(item, add_if_missing=True)\n",
    "    item_mlm.apply(ml_model_meta.model_dump(by_alias=True, exclude_unset=True, exclude_defaults=True))\n",
    "    item_dc = DatacubeExtension.ext(item_mlm.item, add_if_missing=True)\n",
    "    item_dc.apply(dimensions=dimensions, variables=variables)\n",
    "\n",
    "    # --- Now set a fixed flat path ---\n",
    "    item_self_href = Path(\"ml-model-package\") / item_dc.item.id / f\"{item_name}.json\"\n",
    "    item.set_self_href(str(item_self_href))\n",
    "\n",
    "    # --- Add or update catalog, collection and item ---\n",
    "    existing_collection = next((c for c in catalog.get_children() if c.id == collection.id), None)\n",
    "    if not existing_collection:\n",
    "        catalog.add_child(collection)\n",
    "    else:\n",
    "        collection = existing_collection\n",
    "\n",
    "    existing_item = next((i for i in collection.get_all_items() if i.id == item.id), None)\n",
    "    if existing_item:\n",
    "        collection.remove_item(existing_item.id)\n",
    "    collection.add_item(item)\n",
    "\n",
    "    # --- Normalize collection links only ---\n",
    "\n",
    "    # Use '.' as root_href to ensure all relative links are local.\n",
    "    # This avoids absolute paths in the generated STAC JSON\n",
    "    collection.normalize_hrefs(root_href=\".\", strategy=pystac.layout.AsIsLayoutStrategy())\n",
    "\n",
    "    # --- Save collection and item\n",
    "    collection.save_object(include_self_link=True)\n",
    "    item.save_object(include_self_link=True)\n",
    "\n",
    "    # --- Add collection to catalog and save catalog last\n",
    "\n",
    "    # catalog_type=SELF_CONTAINED ensures that all references (collections, items)\n",
    "    # are stored locally within the catalog folder structure respecting relative paths.\n",
    "    # The use of catalog is needed to avoid having absolute paths in the generated STAC JSON file.\n",
    "    catalog.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)\n",
    "\n",
    "    # --- Print relative paths ---\n",
    "    cwd = Path.cwd()\n",
    "    rel_item = Path(item.self_href).relative_to(cwd)\n",
    "    rel_collection = Path(collection.self_href).relative_to(cwd)\n",
    "    print(f\"STAC Item saved to [{rel_item}]\")\n",
    "    print(f\"Collection saved to [{rel_collection}] with {len(list(collection.get_all_items()))} item(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b8daf-9222-4f7e-9557-ac433fbc37ab",
   "metadata": {},
   "source": [
    "## Example Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949873d-8866-455a-8a74-56c08001983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_folder = \"../configs/downscaling\"\n",
    "aggregated_config = config_aggregator(config_folder)\n",
    "stac_item = create_stac_item_from_config(aggregated_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6646ed4-2216-4b06-a750-a36bd6f69c0c",
   "metadata": {},
   "source": [
    "## Validate the collection and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f48cd-8459-4a43-8455-b161bf8e34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_path = \"./ml-model-package/collection.json\"\n",
    "item_path = \"./ml-model-package/unet_rdps_to_hrdps/unet_rdps_to_hrdps.json\"\n",
    "\n",
    "# # --- Load Collection ---\n",
    "collection = pystac.Collection.from_file(collection_path)\n",
    "print(\"Collection loaded successfully\")\n",
    "print(f\"Collection ID: {collection.id}\")\n",
    "print(f\"Number of items: {len(list(collection.get_all_items()))}\")\n",
    "\n",
    "# Validate collection\n",
    "try:\n",
    "    collection.validate()\n",
    "    print(\"Collection is valid\")\n",
    "except STACValidationError as e:\n",
    "    print(f\"Collection validation error: {e}\")\n",
    "\n",
    "# --- Load Item ---\n",
    "item = pystac.Item.from_file(item_path)\n",
    "print(\"\\nItem loaded successfully\")\n",
    "print(f\"Item ID: {item.id}\")\n",
    "\n",
    "try:\n",
    "    item.validate()\n",
    "    print(\"Item is valid\")\n",
    "except STACValidationError as e:\n",
    "    print(f\"Item validation error: {e}\")\n",
    "\n",
    "# list assets and extensions\n",
    "print(\"\\nAssets in item:\")\n",
    "for key, asset in item.assets.items():\n",
    "    print(f\" - {key}: {asset.href}\")\n",
    "\n",
    "print(\"\\nSTAC extensions used in item:\")\n",
    "print(item.stac_extensions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resoterre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
